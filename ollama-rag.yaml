apiVersion: v1
kind: Pod
metadata:
  name: ollama-<username>
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: nvidia.com/gpu.product
            operator: In
            values:
            - NVIDIA-A10
  volumes:
  - name: scratch
    emptyDir: {}
  - name: shm
    emptyDir:
      medium: Memory
      sizeLimit: 8Gi
  containers:
  - name: mypod
    image: ollama/ollama:0.2.8
    resources:
      limits:
        memory: 24Gi
        cpu: 4
        nvidia.com/gpu: 1
      requests:
        memory: 24Gi
        cpu: 4
        nvidia.com/gpu: 1
    command: ["/bin/bash", "-c"]
    args:
    - >-
        apt update;
        apt install -y pip wget vim;
        pip3 install -U langchain-cli==0.0.31;
        pip3 install -U langchain-community==0.3.7;
        pip3 install -U chromadb==0.5.18;
        pip3 install -U sentence-transformers==2.2.2 transformers==4.46.2;
        pip3 install -U huggingface_hub==0.25.2;
        export HOME=/scratch; 
        cd $HOME;
        wget https://www.gutenberg.org/cache/epub/55084/pg55084.txt;
        sleep 3600;
    volumeMounts:
            - name: scratch
              mountPath: /scratch
            - name: shm
              mountPath: /dev/shm
